{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error as sk_mse\n",
    "\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import rmse\n",
    "from fastai.tabular.model import get_emb_sz\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "from dies.data import tp_from_df, get_y_ranges, split_by_year, create_consistent_number_of_sampler_per_day, TimeseriesTransform\n",
    "from dies.utils_pytorch import xavier_init_uniform\n",
    "from dies.autoencoder import Autoencoder\n",
    "from dies.losses import CnnMSELoss\n",
    "from dies.data import *\n",
    "from dies.embedding import EmbeddingModule\n",
    "from dies.data import split_by_year\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sns.set_context('poster')\n",
    "sns.set_style('whitegrid')\n",
    "mpl.rcParams[\"legend.loc\"] = 'upper right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('./data/GEFCOM_Z1.h5') as store:\n",
    "    df = store['powerdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create proper timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TimeUTC = pd.to_datetime(df.TimeUTC, infer_datetime_format=True, utc=True)\n",
    "df.set_index('TimeUTC', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PowerGeneration = df.PowerGeneration.apply(float) / df.MaxPowerGeneration.apply(float)\n",
    "df.drop('MaxPowerGeneration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features for timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DayOfYear'] = df.index.dayofyear\n",
    "df['Hour'] = df.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'WindDirectionMeridional100m',\n",
    "       'WindDirectionMeridional10m', 'WindDirectionZonal100m',\n",
    "       'WindDirectionZonal10m', 'WindSpeed100m', 'WindSpeed10m']\n",
    "\n",
    "cat_cols = ['DayOfYear', 'Hour']\n",
    "\n",
    "df_train, df_test  = split_by_year(df, year=\"2013\")\n",
    "\n",
    "tp = tp_from_df(df_train, y_columns=cols, x_columns=cols, \n",
    "                cat_columns = cat_cols, \n",
    "                standardize_X=True,\n",
    "                valid_percent=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assure correct columns were selected. In case `x` and `y` are the same, we append `_target` for better separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.all_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader for fastai training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = tp.dataloaders(bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = tp.conts.shape[1]\n",
    "sizes_cat = [367, 25]\n",
    "ann_structure = [input_size, 50, 10, input_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_module = EmbeddingModule(sizes_cat, embedding_dropout=0.1)\n",
    "\n",
    "ann_model = Autoencoder(\n",
    "    ann_structure=ann_structure,\n",
    "    embedding_module=embedding_module,\n",
    "    embeding_position=\"start\",\n",
    "    y_ranges=get_y_ranges(dl.train_ds.ys),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dl,\n",
    "    ann_model,\n",
    "    loss_func=torch.nn.MSELoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation...Note, that through `decode` we can reverse the scaling of the input data. See `get_decode_ouput_from_pred` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decode_ouput_from_pred(learn, df_test, column):\n",
    "    df_test = df_test.copy()\n",
    "    test_dl = learn.dls.test_dl(df_test)\n",
    "    tmp = learn.get_preds(dl=test_dl, \n",
    "                          with_input=True, with_decoded=True)\n",
    "    inp = tmp[0]\n",
    "    pred = tmp[1]\n",
    "    \n",
    "    for idx in range(len(learn.dls.train_ds.cont_names)):\n",
    "        inp[1][:,idx] = pred[:, idx]\n",
    "    \n",
    "    inp = learn.dls.decode(inp)\n",
    "    decoded_output = inp.decode()\n",
    "    decoded_output = decoded_output.items\n",
    "    decoded_output.index=df_test.index\n",
    "    \n",
    "    return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_output = get_decode_ouput_from_pred(learn, df_test,\n",
    "                                          \"WindSpeed100m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(decoded_output.WindSpeed100m, \n",
    "            df_test.WindSpeed100m)\n",
    "\n",
    "plt.xlabel('Wind speed [m/s²] Target')\n",
    "plt.ylabel('Wind speed [m/s²] Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.WindSpeed100m, label='Target')\n",
    "plt.plot(decoded_output.WindSpeed100m, label='Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wind speed [m/s²]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test RMSE for WindSpeed: {sk_mse(df_test.WindSpeed100m, decoded_output.WindSpeed100m, squared=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large error might be due to the encoding and decoding on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
